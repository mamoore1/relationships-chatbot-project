{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practicing using NLTK by creating a retrieval-based chatbot. The chatbot responses will be drawn from a selection of reddit comments taken from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subreddit                                               body  \\\n",
      "0  gameofthrones  Your submission has been automatically removed...   \n",
      "1            aww  Dont squeeze her with you massive hand, you me...   \n",
      "2         gaming  It's pretty well known and it was a paid produ...   \n",
      "3           news  You know we have laws against that currently c...   \n",
      "4       politics  Yes, there is a difference between gentle supp...   \n",
      "\n",
      "   controversiality  score  \n",
      "0                 0      1  \n",
      "1                 0     19  \n",
      "2                 0      3  \n",
      "3                 0     10  \n",
      "4                 0      1  \n",
      "1000000\n",
      "40\n",
      "['gameofthrones' 'aww' 'gaming' 'news' 'politics' 'dankmemes'\n",
      " 'relationship_advice' 'nba' 'worldnews' 'AskReddit' 'AmItheAsshole'\n",
      " 'SquaredCircle' 'The_Donald' 'leagueoflegends' 'hockey' 'videos'\n",
      " 'teenagers' 'gonewild' 'movies' 'funny' 'pics' 'marvelstudios' 'memes'\n",
      " 'soccer' 'freefolk' 'MortalKombat' 'todayilearned' 'apexlegends' 'asoiaf'\n",
      " 'Market76' 'Animemes' 'FortNiteBR' 'nfl' 'trashy' 'unpopularopinion'\n",
      " 'ChapoTrapHouse' 'RoastMe' 'Showerthoughts' 'wallstreetbets' 'Pikabu']\n"
     ]
    }
   ],
   "source": [
    "reddit_text_df = pd.read_csv('kaggle_RC_2019-05.csv')\n",
    "\n",
    "# Examining data\n",
    "print(reddit_text_df.head())\n",
    "print(len(reddit_text_df))\n",
    "print(reddit_text_df.subreddit.nunique())\n",
    "print(reddit_text_df.subreddit.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains 1,000,000 reddit posts drawn from 40 subreddits. This is probably too much data for our chatbot to work reasonably quickly; further, some of these subreddits contain a lot of offensive content. I will therefore choose to use responses taken solely from r/relationship_advice, making this a relationship advice chatbot! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "               subreddit                                               body  \\\n",
      "6    relationship_advice  I would be less worried about how he fucked up...   \n",
      "18   relationship_advice  I would actually just like to say that there a...   \n",
      "209  relationship_advice  Do you find it relevant when it happens or if ...   \n",
      "300  relationship_advice  Don't bother giving her the power to make a ch...   \n",
      "342  relationship_advice  If the relationship is not wholly fulfilling, ...   \n",
      "\n",
      "     controversiality  score  \n",
      "6                   0      7  \n",
      "18                  0      0  \n",
      "209                 0      1  \n",
      "300                 0      2  \n",
      "342                 0      1  \n",
      "I would be less worried about how he fucked up in the past and more worried that I still can't get a straight answer about it now.\n"
     ]
    }
   ],
   "source": [
    "relad_df = reddit_text_df[reddit_text_df['subreddit'] == 'relationship_advice']\n",
    "\n",
    "print(len(relad_df))\n",
    "print(relad_df.head())\n",
    "print(relad_df.body.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25000 responses, especially since they are not single sentences, is far too many responses, so we choose only the first 2,500. We next transfer the responses from the Pandas Dataframe into a list and then filter for offensive terms, dropping any responses which contain such terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I would be less worried about how he fucked up in the past and more worried that I still can't get a straight answer about it now.\", \"I would actually just like to say that there are other possibilities at play here.\\n\\nI laughed when I read this, because just today I downloaded tinder because we were discussing dating at our age, and the single people were saying  it's difficult to find cool people.    So I downloaded it, swiped through, and deleted all within 10 minutes.\\n\\nI have 0 interest in other woman, and I love my wife, and there's no way I'm cheating on her....but I still downloaded it.   Btw my wife knows, and thinks it's harmless fun.   \\n\\n So anyway, she might be cheating, but no need to go crazy just yet.\", 'Do you find it relevant when it happens or if the topic happens to come up?', \"Don't bother giving her the power to make a choice. Walk away from her and never look back that way you can keep your dignity! You will thank yourself later in life for standing up for yourself\", \"If the relationship is not wholly fulfilling, it's probably a sign that the two of you aren't meant to be together. Also you are only 18, so while it could be possible, she is likely not the one. People who get together at a young age often don't end up staying together forever. Some do, but I would say, based on what you've said, it doesn't sound like it. Before you said you broke up with her because it didn't feel right, so you were likely right then. What you need to do is sit yourself down and think about whether or not you can continue this relationship. Can the good outweigh the bad or is there too much bad? I can't speak to it, obviously, because I am not you. Ultimately, you need to figure out if you can continue on in this relationship or not.\", \"first off, why would you want to be with someone who's considering you second best? lol be done with her and move on. There's always going to be someone else better out there for her and you're just temporary till that happens\", 'Incest fetishes are suuuuuper common, I think people just tend to see them as more ‘normal’ in men and more something that indicates damage in women, which is bullshit.\\n\\nThat said, just because it’s not gross/weird imho doesn’t mean you have to engage in something you’re not comfortable with, and it’s totally understandable why that’s the case. \\n\\nI would explain all of this to her the same way you did here, and see if she has any alternative ideas at how you could approach it, but otherwise she’s going to have to drop it because pressuring you into sex that makes you uncomfortable should be pretty much game over for the relationship.', 'Part of being in a relationship is getting through the tough stuff. If you think he’s worth it, then rich or poor, hang in there. Just find a safe place to vent, someone that won’t judge him or your relationship unless he is mistreating you personally.', '*multiple times????* also did the guy know your gf was in a relationship? you should beat the shit out of him he he had sex with your gf knowingly.', 'Yes but i was asking what actual evidence you have besides just \"knowing\" im not presuming things about your relationship but people think they know the truth all the time when the reality is quite different.']\n"
     ]
    }
   ],
   "source": [
    "text = [response for response in relad_df.body.iloc[0:2500]]\n",
    "print(text[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263\n",
      "[\"I would actually just like to say that there are other possibilities at play here.\\n\\nI laughed when I read this, because just today I downloaded tinder because we were discussing dating at our age, and the single people were saying  it's difficult to find cool people.    So I downloaded it, swiped through, and deleted all within 10 minutes.\\n\\nI have 0 interest in other woman, and I love my wife, and there's no way I'm cheating on her....but I still downloaded it.   Btw my wife knows, and thinks it's harmless fun.   \\n\\n So anyway, she might be cheating, but no need to go crazy just yet.\", 'Do you find it relevant when it happens or if the topic happens to come up?', \"Don't bother giving her the power to make a choice. Walk away from her and never look back that way you can keep your dignity! You will thank yourself later in life for standing up for yourself\", \"If the relationship is not wholly fulfilling, it's probably a sign that the two of you aren't meant to be together. Also you are only 18, so while it could be possible, she is likely not the one. People who get together at a young age often don't end up staying together forever. Some do, but I would say, based on what you've said, it doesn't sound like it. Before you said you broke up with her because it didn't feel right, so you were likely right then. What you need to do is sit yourself down and think about whether or not you can continue this relationship. Can the good outweigh the bad or is there too much bad? I can't speak to it, obviously, because I am not you. Ultimately, you need to figure out if you can continue on in this relationship or not.\", \"first off, why would you want to be with someone who's considering you second best? lol be done with her and move on. There's always going to be someone else better out there for her and you're just temporary till that happens\", 'Part of being in a relationship is getting through the tough stuff. If you think he’s worth it, then rich or poor, hang in there. Just find a safe place to vent, someone that won’t judge him or your relationship unless he is mistreating you personally.', 'Yes but i was asking what actual evidence you have besides just \"knowing\" im not presuming things about your relationship but people think they know the truth all the time when the reality is quite different.', 'Thanks for the reply, do you think I should just take the bull by the horns and outright just ask if she’s telling the truth?', 'in our case it was minimal contact. less time together.', 'That took me a bit but get down girl, go ahead, get down']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "for item in text:\n",
    "    if re.search(\"cu+nt|\\w*shi+t\\w*|fu+ck\\w*|ni+gg\\w*\", item.lower()):\n",
    "        continue\n",
    "    else:\n",
    "        clean_text.append(item)\n",
    "\n",
    "print(len(clean_text))\n",
    "print(clean_text[0:10])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With profanity removed and the text placed in a list, I will now begin processing the text for use with the chatbot. We will be using NLTKs TfIdfVectorizer and cosine similarity to determine which response would be most appropriate for the chatbot. However, as we want to keep the original version of the responses so that they can be returned by the chatbot, we will separate the data between it's original version and its lemmatized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i would actually just like to say that there are other possibilities at play here\\n\\ni laughed when i read this because just today i downloaded tinder because we were discussing dating at our age and the single people were saying  its difficult to find cool people    so i downloaded it swiped through and deleted all within 10 minutes\\n\\ni have 0 interest in other woman and i love my wife and theres no way im cheating on herbut i still downloaded it   btw my wife knows and thinks its harmless fun   \\n\\n so anyway she might be cheating but no need to go crazy just yet', 'do you find it relevant when it happens or if the topic happens to come up']\n",
      "[[('would', 'MD'), ('actually', 'RB'), ('like', 'VB'), ('say', 'NN'), ('possibilities', 'NNS'), ('play', 'VBP'), ('laughed', 'VBN'), ('read', 'VBP'), ('today', 'NN'), ('downloaded', 'VBD'), ('tinder', 'NN'), ('discussing', 'VBG'), ('dating', 'VBG'), ('age', 'NN'), ('single', 'JJ'), ('people', 'NNS'), ('saying', 'VBG'), ('difficult', 'JJ'), ('find', 'JJ'), ('cool', 'JJ'), ('people', 'NNS'), ('downloaded', 'VBD'), ('swiped', 'VBN'), ('deleted', 'VBN'), ('within', 'IN'), ('10', 'CD'), ('minutes', 'NNS'), ('0', 'CD'), ('interest', 'NN'), ('woman', 'NN'), ('love', 'VB'), ('wife', 'NN'), ('theres', 'NNS'), ('way', 'NN'), ('im', 'IN'), ('cheating', 'VBG'), ('herbut', 'NN'), ('still', 'RB'), ('downloaded', 'VBD'), ('btw', 'JJ'), ('wife', 'NN'), ('knows', 'VBZ'), ('thinks', 'VBZ'), ('harmless', 'JJ'), ('fun', 'NN'), ('anyway', 'RB'), ('might', 'MD'), ('cheating', 'VBG'), ('need', 'VB'), ('go', 'VB'), ('crazy', 'JJ'), ('yet', 'RB')], [('find', 'VB'), ('relevant', 'JJ'), ('happens', 'NNS'), ('topic', 'NN'), ('happens', 'VBZ'), ('come', 'VB')]]\n"
     ]
    }
   ],
   "source": [
    "# Using string.punctuation to remove punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "    punctuation_dictionary = dict((ord(item), None) for item in string.punctuation)\n",
    "    new_text = [item.lower().translate(punctuation_dictionary) for item in text]\n",
    "    return new_text\n",
    "    \n",
    "filtered_text = remove_punct(clean_text)\n",
    "print(filtered_text[0:2])\n",
    "\n",
    "# Using NLKT to tokenize the responses,remove stopwords and tag the parts of speech (for more accurate lemmatization)\n",
    "\n",
    "stop_words = stopwords.words('english') \n",
    "\n",
    "def pos_words(text):\n",
    "    new_text = []\n",
    "    for item in text: # Accessing each response\n",
    "        new_item = []\n",
    "        for word in word_tokenize(item): # Tokenising each response\n",
    "            if word not in stop_words: # Checking the tokenised words against stopwords\n",
    "                new_item.append(word)\n",
    "        pos_new_item = pos_tag(new_item) # Tagging the part of speech for each word\n",
    "        new_text.append(pos_new_item)\n",
    "    return new_text\n",
    "\n",
    "filtered_text = tokenize_words(filtered_text)\n",
    "print(filtered_text[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-ead513c3a910>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmatize_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-131-ead513c3a910>\u001b[0m in \u001b[0;36mlemmatize_text\u001b[1;34m(pos_text)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mnew_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword_tag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mnew_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_tag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mnew_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvironment\\retrieval_chatbot_project\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvironment\\retrieval_chatbot_project\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   1871\u001b[0m         \u001b[1;31m#    find a match or you can't go any further\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m         \u001b[0mexceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m         \u001b[0msubstitutions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPHOLOGICAL_SUBSTITUTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MD'"
     ]
    }
   ],
   "source": [
    "# Lemmatizing our tokenized words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(pos_text):\n",
    "    new_text = []\n",
    "    for response in pos_text:\n",
    "        new_response = []\n",
    "        for word_tag in response:\n",
    "            new_response.append(lemmatizer.lemmatize(word_tag[0], word_tag[1]))\n",
    "        new_text.append(new_response)\n",
    "    return new_text\n",
    "\n",
    "print(lemmatize_text(filtered_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
